{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Object Size Estimation System for AWS SageMaker\n",
        "\n",
        "This notebook provides a complete object size estimation system using SAM (Segment Anything Model) and computer vision techniques. It detects yellow objects and rulers in images, then calculates real-world measurements.\n",
        "\n",
        "## Features\n",
        "- SAM-based object segmentation\n",
        "- HSV color-based yellow object detection\n",
        "- Sequential ruler marking detection with OCR\n",
        "- Automatic calibration and measurement\n",
        "- Enhanced visualization with annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Install Dependencies\n",
        "\n",
        "### Important Notes for AWS SageMaker:\n",
        "\n",
        "**NumPy 2.x Compatibility Issue Fix:**\n",
        "AWS SageMaker often comes with NumPy 2.x pre-installed. If you encounter errors like:\n",
        "- `numpy 1.x cannot be run in numpy 2.2.6`\n",
        "- `numpy.core.multiarray failed to import`\n",
        "- `dtype size changed` errors\n",
        "\n",
        "This happens when packages compiled for NumPy 1.x try to run with NumPy 2.x.\n",
        "\n",
        "**Solution Steps:**\n",
        "1. **DO NOT** downgrade NumPy - keep the existing NumPy 2.x\n",
        "2. Install packages that are compatible with NumPy 2.x (newer versions)\n",
        "3. Restart kernel if you encounter import issues\n",
        "4. Use alternative installation methods if problems persist\n",
        "\n",
        "**Key Changes:**\n",
        "- Uses NumPy 2.x compatible packages (OpenCV ‚â•4.9, Matplotlib ‚â•3.8, etc.)\n",
        "- PyTorch ‚â•2.1.0 with NumPy 2.x support\n",
        "- Latest EasyOCR version (‚â•1.7.1)\n",
        "\n",
        "**AWS SageMaker Specific:**\n",
        "- Uses CPU-only PyTorch for compatibility\n",
        "- All models download automatically to `/tmp/models/`\n",
        "- Processing works on uploaded images in `/tmp/data/`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages compatible with NumPy 2.x (AWS SageMaker default)\n",
        "# Fix compatibility issues by using packages that support NumPy 2.x\n",
        "!pip install --upgrade pip\n",
        "\n",
        "# Check current NumPy version\n",
        "import numpy as np\n",
        "print(f\"Current NumPy version: {np.__version__}\")\n",
        "\n",
        "# Install packages compatible with NumPy 2.x\n",
        "!pip install --upgrade numpy  # Keep the existing NumPy 2.x\n",
        "!pip install opencv-python>=4.9.0  # Supports NumPy 2.x\n",
        "!pip install matplotlib>=3.8.0  # Supports NumPy 2.x  \n",
        "!pip install Pillow>=10.0.0  # Latest version\n",
        "\n",
        "# Install PyTorch with NumPy 2.x support\n",
        "!pip install torch>=2.1.0 torchvision>=0.16.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "\n",
        "# Install SAM\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "\n",
        "# Install EasyOCR latest version (supports NumPy 2.x)\n",
        "!pip install easyocr>=1.7.1\n",
        "\n",
        "print(\"‚úÖ All dependencies installed with NumPy 2.x compatibility!\")\n",
        "print(\"Note: Restart kernel if you encounter import issues.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Alternative Installation (if above fails)\n",
        "\n",
        "If you still encounter NumPy compatibility issues, try this alternative approach:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Alternative installation methods for persistent NumPy 2.x compatibility issues\n",
        "# Run this cell ONLY if the previous installation failed\n",
        "\n",
        "# Method 1: Clean reinstall of all packages\n",
        "# !pip uninstall -y opencv-python matplotlib torch torchvision easyocr\n",
        "# !pip install --no-cache-dir opencv-python>=4.9.0 matplotlib>=3.8.0 \n",
        "# !pip install --no-cache-dir torch>=2.1.0 torchvision>=0.16.0 --index-url https://download.pytorch.org/whl/cpu\n",
        "# !pip install --no-cache-dir easyocr>=1.7.1\n",
        "\n",
        "# Method 2: Force upgrade all packages\n",
        "# !pip install --upgrade --force-reinstall numpy opencv-python matplotlib torch torchvision easyocr\n",
        "\n",
        "# Method 3: Use conda for core packages (if available)\n",
        "# !conda install -c conda-forge numpy opencv matplotlib -y\n",
        "# !pip install torch torchvision easyocr\n",
        "\n",
        "# Method 4: Install specific working versions for NumPy 2.x\n",
        "# !pip install numpy==2.1.0 opencv-python==4.10.0.84 matplotlib==3.9.0 easyocr==1.7.1\n",
        "\n",
        "print(\"Uncomment and run one of the methods above if you encounter issues\")\n",
        "print(\"Always restart kernel after changing package versions\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Verify Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify that all packages can be imported successfully\n",
        "try:\n",
        "    import numpy as np\n",
        "    print(f\"‚úÖ NumPy version: {np.__version__}\")\n",
        "    \n",
        "    import cv2\n",
        "    print(f\"‚úÖ OpenCV version: {cv2.__version__}\")\n",
        "    \n",
        "    import torch\n",
        "    print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
        "    \n",
        "    import easyocr\n",
        "    print(f\"‚úÖ EasyOCR imported successfully\")\n",
        "    \n",
        "    from segment_anything import sam_model_registry, SamPredictor\n",
        "    print(f\"‚úÖ SAM imported successfully\")\n",
        "    \n",
        "    import matplotlib.pyplot as plt\n",
        "    print(f\"‚úÖ Matplotlib imported successfully\")\n",
        "    \n",
        "    from PIL import Image\n",
        "    print(f\"‚úÖ PIL imported successfully\")\n",
        "    \n",
        "    print(\"\\nüéâ All packages imported successfully! Ready to proceed.\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import error: {e}\")\n",
        "    print(\"Please restart kernel and try the alternative installation methods above\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Unexpected error: {e}\")\n",
        "    print(\"Please restart kernel and reinstall dependencies\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Fix Matplotlib NumPy 2.x Issue\n",
        "\n",
        "If matplotlib import fails with `numpy.core.multiarray` error, run this cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix matplotlib NumPy 2.x compatibility issue\n",
        "# Run this ONLY if matplotlib import fails\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    print(\"‚úÖ Matplotlib imports successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Matplotlib import failed: {e}\")\n",
        "    print(\"Attempting to fix...\")\n",
        "    \n",
        "    # Force reinstall matplotlib with NumPy 2.x support\n",
        "    import subprocess\n",
        "    subprocess.run([\"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"matplotlib>=3.8.0\"], check=True)\n",
        "    \n",
        "    # Also reinstall contourpy which often causes issues\n",
        "    subprocess.run([\"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"contourpy\"], check=True)\n",
        "    \n",
        "    print(\"‚úÖ Matplotlib reinstalled. Please restart kernel and try again.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Unexpected error: {e}\")\n",
        "    print(\"Please restart kernel and run the main installation cell again.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import core libraries with enhanced error handling for NumPy 2.x\n",
        "try:\n",
        "    import os\n",
        "    import re\n",
        "    import urllib.request\n",
        "    from typing import List, Dict, Tuple, Optional\n",
        "    \n",
        "    # Check NumPy first\n",
        "    import numpy as np\n",
        "    print(f\"‚úÖ NumPy: {np.__version__}\")\n",
        "    \n",
        "    # Import packages that commonly have NumPy 2.x issues\n",
        "    try:\n",
        "        import cv2\n",
        "        print(f\"‚úÖ OpenCV: {cv2.__version__}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå OpenCV import failed: {e}\")\n",
        "        print(\"Run: !pip install --upgrade --force-reinstall opencv-python\")\n",
        "        raise\n",
        "    \n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        print(\"‚úÖ Matplotlib imported successfully\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå Matplotlib import failed: {e}\")\n",
        "        print(\"This is likely a NumPy 2.x compatibility issue.\")\n",
        "        print(\"Please run the 'Fix Matplotlib NumPy 2.x Issue' cell above.\")\n",
        "        raise\n",
        "    \n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå PyTorch import failed: {e}\")\n",
        "        print(\"Run: !pip install torch>=2.1.0 torchvision>=0.16.0\")\n",
        "        raise\n",
        "    \n",
        "    from PIL import Image\n",
        "    print(\"‚úÖ PIL imported successfully\")\n",
        "    \n",
        "    try:\n",
        "        import easyocr\n",
        "        print(\"‚úÖ EasyOCR imported successfully\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå EasyOCR import failed: {e}\")\n",
        "        print(\"This is likely a NumPy compatibility issue.\")\n",
        "        print(\"Run: !pip install --upgrade --force-reinstall easyocr\")\n",
        "        raise\n",
        "    \n",
        "    # SAM imports\n",
        "    try:\n",
        "        from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
        "        print(\"‚úÖ SAM imported successfully\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå SAM import failed: {e}\")\n",
        "        print(\"Run: !pip install git+https://github.com/facebookresearch/segment-anything.git\")\n",
        "        raise\n",
        "    \n",
        "    print(\"\\nüéâ All libraries imported successfully with NumPy 2.x!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Import failed: {e}\")\n",
        "    print(\"\\nüîß Troubleshooting steps:\")\n",
        "    print(\"1. Restart kernel (Kernel ‚Üí Restart)\")\n",
        "    print(\"2. Run the dependency installation cell again\")\n",
        "    print(\"3. If matplotlib fails, run the matplotlib fix cell\")\n",
        "    print(\"4. Try alternative installation methods if needed\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Download SAM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download SAM model checkpoint\n",
        "# Use /tmp/ directory for AWS SageMaker compatibility\n",
        "models_dir = \"/tmp/models\" if \"/opt/ml\" in os.getcwd() else \"models\"\n",
        "os.makedirs(models_dir, exist_ok=True)\n",
        "\n",
        "# Download SAM ViT-B checkpoint (358MB)\n",
        "checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
        "checkpoint_path = os.path.join(models_dir, \"sam_vit_b_01ec64.pth\")\n",
        "\n",
        "print(f\"Model will be saved to: {checkpoint_path}\")\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(\"Downloading SAM model checkpoint (358MB)...\")\n",
        "    print(\"This may take a few minutes on first run...\")\n",
        "    try:\n",
        "        urllib.request.urlretrieve(checkpoint_url, checkpoint_path)\n",
        "        print(\"‚úÖ Download complete!\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Download failed: {e}\")\n",
        "        print(\"Please check your internet connection and try again.\")\n",
        "        raise\n",
        "else:\n",
        "    print(\"‚úÖ SAM model checkpoint already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Initialize SAM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_sam_model(checkpoint_path: str):\n",
        "    \"\"\"Load SAM model\"\"\"\n",
        "    print(f\"Loading SAM model from {checkpoint_path}\")\n",
        "    \n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"SAM checkpoint not found at {checkpoint_path}\")\n",
        "    \n",
        "    # Load SAM model\n",
        "    sam = sam_model_registry[\"vit_b\"](checkpoint=checkpoint_path)\n",
        "    \n",
        "    # Use CPU for compatibility\n",
        "    device = \"cpu\"\n",
        "    sam.to(device=device)\n",
        "    \n",
        "    predictor = SamPredictor(sam)\n",
        "    print(f\"SAM loaded successfully on {device}\")\n",
        "    \n",
        "    return sam, predictor\n",
        "\n",
        "# Load SAM model\n",
        "sam_model, sam_predictor = load_sam_model(checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_ruler_and_calibrate(image, ocr_reader):\n",
        "    \"\"\"Detect ruler in image and calculate pixel-to-mm conversion ratio\"\"\"\n",
        "    \n",
        "    def extract_numeric_value(text):\n",
        "        \"\"\"Extract numeric value from OCR text\"\"\"\n",
        "        import re\n",
        "        cleaned = re.sub(r'[^\\d.]', '', text)\n",
        "        if cleaned:\n",
        "            try:\n",
        "                return float(cleaned)\n",
        "            except ValueError:\n",
        "                pass\n",
        "        return None\n",
        "    \n",
        "    def preprocess_for_ocr(gray_roi):\n",
        "        \"\"\"Apply multiple preprocessing methods for better OCR\"\"\"\n",
        "        variants = []\n",
        "        \n",
        "        # Original\n",
        "        variants.append((gray_roi.copy(), \"original\"))\n",
        "        \n",
        "        # Adaptive threshold\n",
        "        adaptive = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                       cv2.THRESH_BINARY, 11, 2)\n",
        "        variants.append((adaptive, \"adaptive\"))\n",
        "        \n",
        "        # Otsu threshold\n",
        "        _, otsu = cv2.threshold(gray_roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        variants.append((otsu, \"otsu\"))\n",
        "        \n",
        "        # Inverted adaptive\n",
        "        adaptive_inv = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                           cv2.THRESH_BINARY_INV, 11, 2)\n",
        "        variants.append((adaptive_inv, \"adaptive_inv\"))\n",
        "        \n",
        "        return variants\n",
        "    \n",
        "    try:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Find ruler regions using edge detection\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        ruler_regions = []\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area < 500:\n",
        "                continue\n",
        "                \n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            aspect_ratio = max(w, h) / min(w, h)\n",
        "            \n",
        "            # Rulers are typically long and narrow\n",
        "            if aspect_ratio > 2.0 and max(w, h) > 100:\n",
        "                ruler_regions.append((x, y, w, h, area))\n",
        "        \n",
        "        # Sort by area (larger regions first)\n",
        "        ruler_regions.sort(key=lambda x: x[4], reverse=True)\n",
        "        \n",
        "        best_calibration = None\n",
        "        best_confidence = 0\n",
        "        \n",
        "        # Try top ruler candidates\n",
        "        for x, y, w, h, area in ruler_regions[:3]:\n",
        "            roi = image[y:y+h, x:x+w]\n",
        "            gray_roi = gray[y:y+h, x:x+w]\n",
        "            \n",
        "            markings = []\n",
        "            \n",
        "            # Try different preprocessing and orientations\n",
        "            variants = preprocess_for_ocr(gray_roi)\n",
        "            \n",
        "            for processed_img, desc in variants:\n",
        "                # Try original and rotated orientations\n",
        "                for rotation, rot_desc in [(processed_img, \"normal\"), \n",
        "                                         (cv2.rotate(processed_img, cv2.ROTATE_90_CLOCKWISE), \"rot90\")]:\n",
        "                    \n",
        "                    # OCR with EasyOCR\n",
        "                    try:\n",
        "                        results = ocr_reader.readtext(rotation, paragraph=False)\n",
        "                        \n",
        "                        for (bbox, text, confidence) in results:\n",
        "                            if confidence < 0.3:\n",
        "                                continue\n",
        "                                \n",
        "                            numeric_value = extract_numeric_value(text)\n",
        "                            if numeric_value is not None and 0 <= numeric_value <= 100:\n",
        "                                # Calculate position\n",
        "                                x_coords = [point[0] for point in bbox]\n",
        "                                center_x = np.mean(x_coords)\n",
        "                                \n",
        "                                markings.append({\n",
        "                                    'value': numeric_value,\n",
        "                                    'confidence': confidence,\n",
        "                                    'position': center_x,\n",
        "                                    'text': text\n",
        "                                })\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "            \n",
        "            # Calculate calibration from markings\n",
        "            if len(markings) >= 2:\n",
        "                markings.sort(key=lambda m: m['position'])\n",
        "                \n",
        "                ratios = []\n",
        "                for i in range(len(markings) - 1):\n",
        "                    mark1, mark2 = markings[i], markings[i + 1]\n",
        "                    pixel_dist = abs(mark2['position'] - mark1['position'])\n",
        "                    unit_dist = mark2['value'] - mark1['value']\n",
        "                    \n",
        "                    if unit_dist > 0 and pixel_dist > 10:\n",
        "                        # Assume centimeters and convert to mm\n",
        "                        px_per_mm = pixel_dist / (unit_dist * 10)\n",
        "                        ratios.append(px_per_mm)\n",
        "                \n",
        "                if ratios:\n",
        "                    avg_ratio = np.mean(ratios)\n",
        "                    confidence = max(0.1, 1.0 - np.std(ratios) / avg_ratio) if len(ratios) > 1 else 0.7\n",
        "                    \n",
        "                    if confidence > best_confidence:\n",
        "                        best_calibration = {\n",
        "                            'px_per_mm': avg_ratio,\n",
        "                            'confidence': confidence,\n",
        "                            'markings_found': len(markings),\n",
        "                            'method': 'ruler_detection',\n",
        "                            'markings': [f\"{m['value']:.0f}cm\" for m in markings],\n",
        "                            'ruler_region': (x, y, w, h),\n",
        "                            'marking_positions': [(m['position'] + x, y + h//2, f\"{m['value']:.0f}cm\") for m in markings]\n",
        "                        }\n",
        "                        best_confidence = confidence\n",
        "        \n",
        "        if best_calibration:\n",
        "            return best_calibration\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Ruler detection failed, using default calibration\")\n",
        "            return {\n",
        "                'px_per_mm': 30.0,\n",
        "                'confidence': 0.3,\n",
        "                'markings_found': 0,\n",
        "                'method': 'default_fallback',\n",
        "                'markings': [],\n",
        "                'ruler_region': None,\n",
        "                'marking_positions': []\n",
        "            }\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Ruler detection error: {e}, using default calibration\")\n",
        "        return {\n",
        "            'px_per_mm': 30.0,\n",
        "            'confidence': 0.3,\n",
        "            'markings_found': 0,\n",
        "            'method': 'default_fallback',\n",
        "            'markings': [],\n",
        "            'ruler_region': None,\n",
        "            'marking_positions': []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_ruler_visualization(image, calibration):\n",
        "    \"\"\"Draw ruler region and markings on the visualization\"\"\"\n",
        "    \n",
        "    if calibration['ruler_region'] is None or calibration['markings_found'] == 0:\n",
        "        return image\n",
        "    \n",
        "    vis_image = image.copy()\n",
        "    x, y, w, h = calibration['ruler_region']\n",
        "    \n",
        "    # Draw ruler region with green rectangle\n",
        "    cv2.rectangle(vis_image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "    \n",
        "    # Add ruler region label\n",
        "    ruler_label = f\"Ruler Region ({calibration['method']})\"\n",
        "    cv2.putText(vis_image, ruler_label, (x, y-10), \n",
        "               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "    \n",
        "    # Draw individual ruler markings\n",
        "    for pos_x, pos_y, marking_text in calibration['marking_positions']:\n",
        "        # Draw marking point\n",
        "        cv2.circle(vis_image, (int(pos_x), int(pos_y)), 4, (0, 255, 255), -1)\n",
        "        \n",
        "        # Add marking text with background rectangle for visibility\n",
        "        text_size = cv2.getTextSize(marking_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]\n",
        "        text_x = int(pos_x - text_size[0]//2)\n",
        "        text_y = int(pos_y - 15)\n",
        "        \n",
        "        # Background rectangle\n",
        "        cv2.rectangle(vis_image, (text_x-2, text_y-text_size[1]-2), \n",
        "                     (text_x+text_size[0]+2, text_y+2), (0, 0, 0), -1)\n",
        "        \n",
        "        # Text\n",
        "        cv2.putText(vis_image, marking_text, (text_x, text_y), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)\n",
        "    \n",
        "    # Add calibration info\n",
        "    calib_info = f\"Calibration: {calibration['px_per_mm']:.2f} px/mm\"\n",
        "    confidence_info = f\"Confidence: {calibration['confidence']:.2f}\"\n",
        "    markings_info = f\"Markings: {', '.join(calibration['markings'])}\"\n",
        "    \n",
        "    # Draw calibration info with background\n",
        "    y_offset = vis_image.shape[0] - 60\n",
        "    \n",
        "    for i, text in enumerate([calib_info, confidence_info, markings_info]):\n",
        "        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
        "        text_y = y_offset + i * 20\n",
        "        \n",
        "        # Background rectangle\n",
        "        cv2.rectangle(vis_image, (8, text_y - text_size[1] - 2), \n",
        "                     (text_size[0] + 12, text_y + 2), (0, 0, 0), -1)\n",
        "        \n",
        "        # Text\n",
        "        cv2.putText(vis_image, text, (10, text_y), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
        "    \n",
        "    return vis_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### üîß Manual Update Required for Ruler Detection\n",
        "\n",
        "**IMPORTANT:** To enable ruler detection with enhanced visualization, you need to manually update the `measure_objects_in_image()` function in the cell above.\n",
        "\n",
        "**Step 1:** Replace this line:\n",
        "```python\n",
        "px_per_mm = 30.0  # This is a placeholder - you can implement ruler detection\n",
        "```\n",
        "\n",
        "**With this code:**\n",
        "```python\n",
        "# Ruler-based calibration\n",
        "print(\"Performing ruler detection and calibration...\")\n",
        "calibration = detect_ruler_and_calibrate(resized_image, ocr_reader)\n",
        "px_per_mm = calibration['px_per_mm']\n",
        "\n",
        "print(f\"Calibration: {px_per_mm:.3f} px/mm (method: {calibration['method']}, confidence: {calibration['confidence']:.2f})\")\n",
        "if calibration['markings_found'] > 0:\n",
        "    print(f\"Found {calibration['markings_found']} ruler markings: {calibration['markings']}\")\n",
        "```\n",
        "\n",
        "**Step 2:** Replace the visualization section:\n",
        "```python\n",
        "# Create simple visualization\n",
        "vis_image = resized_image.copy()\n",
        "```\n",
        "\n",
        "**With:**\n",
        "```python\n",
        "# Create enhanced visualization with ruler markings\n",
        "vis_image = resized_image.copy()\n",
        "\n",
        "# Add ruler visualization if detection was successful\n",
        "if 'calibration' in locals():\n",
        "    vis_image = draw_ruler_visualization(vis_image, calibration)\n",
        "```\n",
        "\n",
        "**Step 3:** Update the return statement to include full calibration data:\n",
        "```python\n",
        "'calibration': calibration  # instead of {'px_per_mm': px_per_mm, 'method': 'default'}\n",
        "```\n",
        "\n",
        "After making these changes, the system will display:\n",
        "- **Green rectangle** around detected ruler region\n",
        "- **Yellow circles** marking each detected ruler number\n",
        "- **Number labels** with units (e.g., \"3cm\", \"4cm\", \"5cm\")\n",
        "- **Calibration information** at the bottom of the image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXAMPLE: Enhanced Measurement Function with Ruler Visualization\n",
        "# Use this as reference to update the measurement function above\n",
        "\n",
        "def measure_objects_in_image_enhanced(image_path: str, sam_model, sam_predictor, ocr_reader, display=True):\n",
        "    \"\"\"Complete measurement pipeline with ruler detection and enhanced visualization\"\"\"\n",
        "    \n",
        "    print(f\"SAM MEASUREMENT SYSTEM: {image_path}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        original_image, resized_image, scale_x, scale_y = load_and_preprocess_image(image_path)\n",
        "        \n",
        "        # Detect yellow objects\n",
        "        yellow_objects = detect_yellow_objects_hsv(resized_image)\n",
        "        print(f\"Detection found {len(yellow_objects)} yellow objects\")\n",
        "        \n",
        "        if not yellow_objects:\n",
        "            print(\"No yellow objects found\")\n",
        "            return None\n",
        "        \n",
        "        # Ruler-based calibration\n",
        "        print(\"Performing ruler detection and calibration...\")\n",
        "        calibration = detect_ruler_and_calibrate(resized_image, ocr_reader)\n",
        "        px_per_mm = calibration['px_per_mm']\n",
        "        \n",
        "        print(f\"Calibration: {px_per_mm:.3f} px/mm (method: {calibration['method']}, confidence: {calibration['confidence']:.2f})\")\n",
        "        if calibration['markings_found'] > 0:\n",
        "            print(f\"Found {calibration['markings_found']} ruler markings: {calibration['markings']}\")\n",
        "        \n",
        "        # Measure objects\n",
        "        measurements = []\n",
        "        for i, obj in enumerate(yellow_objects):\n",
        "            # Get oriented bounding box\n",
        "            rect = cv2.minAreaRect(obj['contour'])\n",
        "            width_px, height_px = rect[1]\n",
        "            \n",
        "            # Ensure width > height\n",
        "            if height_px > width_px:\n",
        "                width_px, height_px = height_px, width_px\n",
        "            \n",
        "            # Convert to real world units\n",
        "            width_mm = width_px / px_per_mm\n",
        "            height_mm = height_px / px_per_mm\n",
        "            \n",
        "            measurement = {\n",
        "                'object_id': i + 1,\n",
        "                'width_mm': width_mm,\n",
        "                'height_mm': height_mm,\n",
        "                'width_inch': width_mm / 25.4,\n",
        "                'height_inch': height_mm / 25.4,\n",
        "                'width_px': width_px,\n",
        "                'height_px': height_px,\n",
        "                'area_px': obj['area']\n",
        "            }\n",
        "            measurements.append(measurement)\n",
        "        \n",
        "        print(f\"\\nSUCCESS!\")\n",
        "        \n",
        "        for measurement in measurements:\n",
        "            print(f\"   Object {measurement['object_id']}: {measurement['width_mm']:.1f} x {measurement['height_mm']:.1f} mm\")\n",
        "            print(f\"      ({measurement['width_inch']:.2f} x {measurement['height_inch']:.2f} inches)\")\n",
        "        \n",
        "        # Create enhanced visualization with ruler markings\n",
        "        vis_image = resized_image.copy()\n",
        "        \n",
        "        # Add ruler visualization first\n",
        "        vis_image = draw_ruler_visualization(vis_image, calibration)\n",
        "        \n",
        "        # Draw yellow objects on top\n",
        "        for i, obj in enumerate(yellow_objects):\n",
        "            bbox = obj['bbox']\n",
        "            x, y, w, h = bbox\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(vis_image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "            \n",
        "            # Add measurement text with background for better visibility\n",
        "            if i < len(measurements):\n",
        "                measurement = measurements[i]\n",
        "                text = f\"Obj {measurement['object_id']}: {measurement['width_mm']:.1f}x{measurement['height_mm']:.1f}mm\"\n",
        "                \n",
        "                # Calculate text size for background\n",
        "                text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]\n",
        "                \n",
        "                # Background rectangle\n",
        "                cv2.rectangle(vis_image, (x-2, y-text_size[1]-12), \n",
        "                             (x+text_size[0]+2, y-2), (0, 0, 0), -1)\n",
        "                \n",
        "                # Text\n",
        "                cv2.putText(vis_image, text, (x, y-10), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        \n",
        "        # Add enhanced title\n",
        "        title = 'Object Measurement with Ruler Detection'\n",
        "        title_size = cv2.getTextSize(title, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
        "        cv2.rectangle(vis_image, (8, 8), (title_size[0]+12, 40), (0, 0, 0), -1)\n",
        "        cv2.putText(vis_image, title, (10, 30), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "        \n",
        "        if display:\n",
        "            plt.figure(figsize=(15, 10))\n",
        "            plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(f\"Enhanced Measurement Results - {os.path.basename(image_path)}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        \n",
        "        return {\n",
        "            'success': True,\n",
        "            'yellow_objects': yellow_objects,\n",
        "            'measurements': measurements,\n",
        "            'visualization': vis_image,\n",
        "            'original_image': original_image,\n",
        "            'resized_image': resized_image,\n",
        "            'calibration': calibration\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return {'success': False, 'error': str(e)}\n",
        "\n",
        "print(\"Enhanced measurement function example created!\")\n",
        "print(\"Copy the relevant parts to update the main measurement function above.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_ruler_and_calibrate(image, ocr_reader):\n",
        "    \"\"\"Detect ruler in image and calculate pixel-to-mm conversion ratio\"\"\"\n",
        "    \n",
        "    def extract_numeric_value(text):\n",
        "        \"\"\"Extract numeric value from OCR text\"\"\"\n",
        "        import re\n",
        "        cleaned = re.sub(r'[^\\d.]', '', text)\n",
        "        if cleaned:\n",
        "            try:\n",
        "                return float(cleaned)\n",
        "            except ValueError:\n",
        "                pass\n",
        "        return None\n",
        "    \n",
        "    def preprocess_for_ocr(gray_roi):\n",
        "        \"\"\"Apply multiple preprocessing methods for better OCR\"\"\"\n",
        "        variants = []\n",
        "        \n",
        "        # Original\n",
        "        variants.append((gray_roi.copy(), \"original\"))\n",
        "        \n",
        "        # Adaptive threshold\n",
        "        adaptive = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                       cv2.THRESH_BINARY, 11, 2)\n",
        "        variants.append((adaptive, \"adaptive\"))\n",
        "        \n",
        "        # Otsu threshold\n",
        "        _, otsu = cv2.threshold(gray_roi, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "        variants.append((otsu, \"otsu\"))\n",
        "        \n",
        "        # Inverted adaptive\n",
        "        adaptive_inv = cv2.adaptiveThreshold(gray_roi, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
        "                                           cv2.THRESH_BINARY_INV, 11, 2)\n",
        "        variants.append((adaptive_inv, \"adaptive_inv\"))\n",
        "        \n",
        "        return variants\n",
        "    \n",
        "    try:\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Find ruler regions using edge detection\n",
        "        edges = cv2.Canny(gray, 50, 150)\n",
        "        contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        \n",
        "        ruler_regions = []\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "            if area < 500:\n",
        "                continue\n",
        "                \n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "            aspect_ratio = max(w, h) / min(w, h)\n",
        "            \n",
        "            # Rulers are typically long and narrow\n",
        "            if aspect_ratio > 2.0 and max(w, h) > 100:\n",
        "                ruler_regions.append((x, y, w, h, area))\n",
        "        \n",
        "        # Sort by area (larger regions first)\n",
        "        ruler_regions.sort(key=lambda x: x[4], reverse=True)\n",
        "        \n",
        "        best_calibration = None\n",
        "        best_confidence = 0\n",
        "        \n",
        "        # Try top ruler candidates\n",
        "        for x, y, w, h, area in ruler_regions[:3]:\n",
        "            roi = image[y:y+h, x:x+w]\n",
        "            gray_roi = gray[y:y+h, x:x+w]\n",
        "            \n",
        "            markings = []\n",
        "            \n",
        "            # Try different preprocessing and orientations\n",
        "            variants = preprocess_for_ocr(gray_roi)\n",
        "            \n",
        "            for processed_img, desc in variants:\n",
        "                # Try original and rotated orientations\n",
        "                for rotation, rot_desc in [(processed_img, \"normal\"), \n",
        "                                         (cv2.rotate(processed_img, cv2.ROTATE_90_CLOCKWISE), \"rot90\")]:\n",
        "                    \n",
        "                    # OCR with EasyOCR\n",
        "                    try:\n",
        "                        results = ocr_reader.readtext(rotation, paragraph=False)\n",
        "                        \n",
        "                        for (bbox, text, confidence) in results:\n",
        "                            if confidence < 0.3:\n",
        "                                continue\n",
        "                                \n",
        "                            numeric_value = extract_numeric_value(text)\n",
        "                            if numeric_value is not None and 0 <= numeric_value <= 100:\n",
        "                                # Calculate position\n",
        "                                x_coords = [point[0] for point in bbox]\n",
        "                                center_x = np.mean(x_coords)\n",
        "                                \n",
        "                                markings.append({\n",
        "                                    'value': numeric_value,\n",
        "                                    'confidence': confidence,\n",
        "                                    'position': center_x,\n",
        "                                    'text': text\n",
        "                                })\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "            \n",
        "            # Calculate calibration from markings\n",
        "            if len(markings) >= 2:\n",
        "                markings.sort(key=lambda m: m['position'])\n",
        "                \n",
        "                ratios = []\n",
        "                for i in range(len(markings) - 1):\n",
        "                    mark1, mark2 = markings[i], markings[i + 1]\n",
        "                    pixel_dist = abs(mark2['position'] - mark1['position'])\n",
        "                    unit_dist = mark2['value'] - mark1['value']\n",
        "                    \n",
        "                    if unit_dist > 0 and pixel_dist > 10:\n",
        "                        # Assume centimeters and convert to mm\n",
        "                        px_per_mm = pixel_dist / (unit_dist * 10)\n",
        "                        ratios.append(px_per_mm)\n",
        "                \n",
        "                if ratios:\n",
        "                    avg_ratio = np.mean(ratios)\n",
        "                    confidence = max(0.1, 1.0 - np.std(ratios) / avg_ratio) if len(ratios) > 1 else 0.7\n",
        "                    \n",
        "                    if confidence > best_confidence:\n",
        "                        best_calibration = {\n",
        "                            'px_per_mm': avg_ratio,\n",
        "                            'confidence': confidence,\n",
        "                            'markings_found': len(markings),\n",
        "                            'method': 'ruler_detection',\n",
        "                            'markings': [f\"{m['value']}{m.get('unit', 'cm')}\" for m in markings]\n",
        "                        }\n",
        "                        best_confidence = confidence\n",
        "        \n",
        "        if best_calibration:\n",
        "            return best_calibration\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  Ruler detection failed, using default calibration\")\n",
        "            return {\n",
        "                'px_per_mm': 30.0,\n",
        "                'confidence': 0.3,\n",
        "                'markings_found': 0,\n",
        "                'method': 'default_fallback',\n",
        "                'markings': []\n",
        "            }\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Ruler detection error: {e}, using default calibration\")\n",
        "        return {\n",
        "            'px_per_mm': 30.0,\n",
        "            'confidence': 0.3,\n",
        "            'markings_found': 0,\n",
        "            'method': 'default_fallback',\n",
        "            'markings': []\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Initialize OCR Reader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize OCR reader\n",
        "print(\"Initializing OCR reader...\")\n",
        "ocr_reader = easyocr.Reader(['en'])\n",
        "print(\"OCR reader initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Core Functions\n",
        "\n",
        "### Image Processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image(image: np.ndarray, max_size: int = 800) -> np.ndarray:\n",
        "    \"\"\"Resize image for SAM processing\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    if max(h, w) > max_size:\n",
        "        scale = max_size / max(h, w)\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        image = cv2.resize(image, (new_w, new_h))\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image_path: str):\n",
        "    \"\"\"Load and preprocess image\"\"\"\n",
        "    # Load image\n",
        "    original_image = cv2.imread(image_path)\n",
        "    if original_image is None:\n",
        "        raise ValueError(f\"Could not load image from {image_path}\")\n",
        "    \n",
        "    print(f\"Original image: {original_image.shape[1]}x{original_image.shape[0]}\")\n",
        "    \n",
        "    # Resize for processing\n",
        "    resized_image = resize_image(original_image)\n",
        "    print(f\"Resized image: {resized_image.shape[1]}x{resized_image.shape[0]}\")\n",
        "    \n",
        "    # Calculate scale factors\n",
        "    scale_x = resized_image.shape[1] / original_image.shape[1]\n",
        "    scale_y = resized_image.shape[0] / original_image.shape[0]\n",
        "    \n",
        "    return original_image, resized_image, scale_x, scale_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Yellow Object Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_yellow_objects_hsv(image: np.ndarray) -> List[Dict]:\n",
        "    \"\"\"Yellow object detection using HSV color space\"\"\"\n",
        "    print(\"\\n=== YELLOW OBJECT DETECTION ===\")\n",
        "    \n",
        "    # Convert to HSV for better color detection\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    \n",
        "    # Define yellow color range in HSV\n",
        "    lower_yellow = np.array([15, 50, 50])\n",
        "    upper_yellow = np.array([35, 255, 255])\n",
        "    \n",
        "    # Create binary mask for yellow regions\n",
        "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "    \n",
        "    # Morphological operations for noise reduction\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "    \n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    print(f\"  Found {len(contours)} contours\")\n",
        "    \n",
        "    # Process contours with filtering\n",
        "    candidates = []\n",
        "    \n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        \n",
        "        # Filter by area\n",
        "        if area < 1000:\n",
        "            continue\n",
        "        \n",
        "        # Calculate bounding rectangle\n",
        "        bbox = cv2.boundingRect(contour)\n",
        "        x, y, w, h = bbox\n",
        "        \n",
        "        # Calculate aspect ratio\n",
        "        aspect_ratio = max(w, h) / min(w, h)\n",
        "        \n",
        "        # Filter by aspect ratio\n",
        "        if aspect_ratio > 5:\n",
        "            continue\n",
        "        \n",
        "        # Calculate quality metrics\n",
        "        hull = cv2.convexHull(contour)\n",
        "        hull_area = cv2.contourArea(hull)\n",
        "        solidity = area / hull_area if hull_area > 0 else 0\n",
        "        extent = area / (w * h)\n",
        "        \n",
        "        # Quality score\n",
        "        quality_score = (solidity * 0.4 + extent * 0.4 + min(1.0, area / 5000) * 0.2)\n",
        "        \n",
        "        # Only accept high-quality detections\n",
        "        if quality_score > 0.5:\n",
        "            candidates.append({\n",
        "                'contour': contour,\n",
        "                'bbox': bbox,\n",
        "                'area': area,\n",
        "                'aspect_ratio': aspect_ratio,\n",
        "                'solidity': solidity,\n",
        "                'extent': extent,\n",
        "                'quality_score': quality_score,\n",
        "                'method': 'hsv'\n",
        "            })\n",
        "    \n",
        "    print(f\"  After filtering: {len(candidates)} candidates\")\n",
        "    \n",
        "    # Sort by quality score\n",
        "    candidates.sort(key=lambda x: x['quality_score'], reverse=True)\n",
        "    \n",
        "    # Remove overlapping detections\n",
        "    final_objects = []\n",
        "    for candidate in candidates:\n",
        "        is_duplicate = False\n",
        "        for existing in final_objects:\n",
        "            if calculate_bbox_overlap(candidate['bbox'], existing['bbox']) > 0.3:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "        \n",
        "        if not is_duplicate:\n",
        "            final_objects.append(candidate)\n",
        "    \n",
        "    print(f\"  Final objects: {len(final_objects)}\")\n",
        "    for i, obj in enumerate(final_objects):\n",
        "        print(f\"    Object {i+1}: area={obj['area']}, quality={obj['quality_score']:.2f}\")\n",
        "    \n",
        "    return final_objects\n",
        "\n",
        "def calculate_bbox_overlap(bbox1: Tuple[int, int, int, int], bbox2: Tuple[int, int, int, int]) -> float:\n",
        "    \"\"\"Calculate overlap ratio between two bounding boxes\"\"\"\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "    \n",
        "    # Calculate intersection\n",
        "    left = max(x1, x2)\n",
        "    top = max(y1, y2)\n",
        "    right = min(x1 + w1, x2 + w2)\n",
        "    bottom = min(y1 + h1, y2 + h2)\n",
        "    \n",
        "    if left < right and top < bottom:\n",
        "        intersection = (right - left) * (bottom - top)\n",
        "        area1 = w1 * h1\n",
        "        area2 = w2 * h2\n",
        "        union = area1 + area2 - intersection\n",
        "        return intersection / union if union > 0 else 0\n",
        "    \n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Main Measurement Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def measure_objects_in_image(image_path: str, sam_model, sam_predictor, ocr_reader, display=True):\n",
        "    \"\"\"Complete measurement pipeline - functional approach\"\"\"\n",
        "    \n",
        "    print(f\"SAM MEASUREMENT SYSTEM: {image_path}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        original_image, resized_image, scale_x, scale_y = load_and_preprocess_image(image_path)\n",
        "        \n",
        "        # Detect yellow objects\n",
        "        yellow_objects = detect_yellow_objects_hsv(resized_image)\n",
        "        print(f\"Detection found {len(yellow_objects)} yellow objects\")\n",
        "        \n",
        "        if not yellow_objects:\n",
        "            print(\"No yellow objects found\")\n",
        "            return None\n",
        "        \n",
        "        # Simple calibration (assume 30 pixels per mm as default)\n",
        "        # In a real scenario, you would implement ruler detection here\n",
        "        px_per_mm = 30.0  # This is a placeholder - you can implement ruler detection\n",
        "        \n",
        "        # Measure objects\n",
        "        measurements = []\n",
        "        for i, obj in enumerate(yellow_objects):\n",
        "            # Get oriented bounding box\n",
        "            rect = cv2.minAreaRect(obj['contour'])\n",
        "            width_px, height_px = rect[1]\n",
        "            \n",
        "            # Ensure width > height\n",
        "            if height_px > width_px:\n",
        "                width_px, height_px = height_px, width_px\n",
        "            \n",
        "            # Convert to real world units\n",
        "            width_mm = width_px / px_per_mm\n",
        "            height_mm = height_px / px_per_mm\n",
        "            \n",
        "            measurement = {\n",
        "                'object_id': i + 1,\n",
        "                'width_mm': width_mm,\n",
        "                'height_mm': height_mm,\n",
        "                'width_inch': width_mm / 25.4,\n",
        "                'height_inch': height_mm / 25.4,\n",
        "                'width_px': width_px,\n",
        "                'height_px': height_px,\n",
        "                'area_px': obj['area']\n",
        "            }\n",
        "            measurements.append(measurement)\n",
        "        \n",
        "        print(f\"\\nSUCCESS!\")\n",
        "        \n",
        "        for measurement in measurements:\n",
        "            print(f\"   Object {measurement['object_id']}: {measurement['width_mm']:.1f} x {measurement['height_mm']:.1f} mm\")\n",
        "            print(f\"      ({measurement['width_inch']:.2f} x {measurement['height_inch']:.2f} inches)\")\n",
        "        \n",
        "        # Create simple visualization\n",
        "        vis_image = resized_image.copy()\n",
        "        \n",
        "        # Draw yellow objects\n",
        "        for i, obj in enumerate(yellow_objects):\n",
        "            bbox = obj['bbox']\n",
        "            x, y, w, h = bbox\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(vis_image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "            \n",
        "            # Add measurement text\n",
        "            if i < len(measurements):\n",
        "                measurement = measurements[i]\n",
        "                text = f\"Obj {measurement['object_id']}: {measurement['width_mm']:.1f}x{measurement['height_mm']:.1f}mm\"\n",
        "                cv2.putText(vis_image, text, (x, y-10), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        \n",
        "        # Add title\n",
        "        cv2.putText(vis_image, 'Object Measurement Results', (10, 30), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "        \n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(f\"Measurement Results - {os.path.basename(image_path)}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        \n",
        "        return {\n",
        "            'success': True,\n",
        "            'yellow_objects': yellow_objects,\n",
        "            'measurements': measurements,\n",
        "            'visualization': vis_image,\n",
        "            'original_image': original_image,\n",
        "            'resized_image': resized_image,\n",
        "            'calibration': {'px_per_mm': px_per_mm, 'method': 'default'}\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return {'success': False, 'error': str(e)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Usage Instructions\n",
        "\n",
        "### Step 1: Upload Your Images\n",
        "Upload your test images to the SageMaker environment. Create a folder called 'test_images' and place your images there.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directories for test images and outputs\n",
        "os.makedirs('test_images', exist_ok=True)\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "print(\"Directories created. Please upload your test images to the 'test_images' folder.\")\n",
        "print(\"You can use the file browser on the left to upload images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 2: Process Your Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all images in the test_images folder\n",
        "test_images = []\n",
        "if os.path.exists('test_images'):\n",
        "    for filename in os.listdir('test_images'):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "            test_images.append(os.path.join('test_images', filename))\n",
        "\n",
        "print(f\"Found {len(test_images)} test images:\")\n",
        "for img in test_images:\n",
        "    print(f\"  - {img}\")\n",
        "\n",
        "if not test_images:\n",
        "    print(\"No test images found. Please upload images to the 'test_images' folder.\")\n",
        "    print(\"Supported formats: .jpg, .jpeg, .png, .bmp\")\n",
        "\n",
        "# Process each image\n",
        "results = []\n",
        "for image_path in test_images:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSING: {image_path}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Run measurement system\n",
        "    result = measure_objects_in_image(image_path, sam_model, sam_predictor, ocr_reader, display=True)\n",
        "    \n",
        "    if result and result['success']:\n",
        "        results.append(result)\n",
        "        \n",
        "        # Save visualization\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        output_path = f'output/{base_name}_measurement_result.jpg'\n",
        "        cv2.imwrite(output_path, result['visualization'])\n",
        "        print(f\"\\nSaved visualization: {output_path}\")\n",
        "    else:\n",
        "        print(f\"\\nFailed to process {image_path}\")\n",
        "\n",
        "print(f\"\\n\\nProcessing complete! Successfully processed {len(results)} images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 3: Process Individual Images\n",
        "\n",
        "Use this cell to process a single specific image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process a single image\n",
        "# Replace 'your_image_path.jpg' with the actual path to your image\n",
        "single_image_path = 'test_images/your_image_path.jpg'\n",
        "\n",
        "if os.path.exists(single_image_path):\n",
        "    result = measure_objects_in_image(single_image_path, sam_model, sam_predictor, ocr_reader, display=True)\n",
        "    \n",
        "    if result and result['success']:\n",
        "        print(\"\\nProcessing successful!\")\n",
        "        \n",
        "        # Save result\n",
        "        base_name = os.path.splitext(os.path.basename(single_image_path))[0]\n",
        "        output_path = f'output/{base_name}_detailed_result.jpg'\n",
        "        cv2.imwrite(output_path, result['visualization'])\n",
        "        print(f\"\\nSaved detailed result: {output_path}\")\n",
        "    else:\n",
        "        print(\"Processing failed!\")\n",
        "else:\n",
        "    print(f\"Image not found: {single_image_path}\")\n",
        "    print(\"Please update the path to point to your image file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Summary and Results\n",
        "\n",
        "### View Output Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all output files\n",
        "output_files = []\n",
        "if os.path.exists('output'):\n",
        "    for filename in os.listdir('output'):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            output_files.append(os.path.join('output', filename))\n",
        "\n",
        "print(f\"Generated {len(output_files)} output files:\")\n",
        "for file in output_files:\n",
        "    file_size = os.path.getsize(file) / 1024  # Size in KB\n",
        "    print(f\"  - {file} ({file_size:.1f} KB)\")\n",
        "\n",
        "print(\"\\nYou can download these files using the file browser on the left.\")\n",
        "\n",
        "# Create summary of results\n",
        "if 'results' in locals() and results:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MEASUREMENT SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"\\nImage {i+1}:\")\n",
        "        print(f\"  Objects detected: {len(result['yellow_objects'])}\")\n",
        "        print(f\"  Calibration: {result['calibration']['px_per_mm']:.2f} px/mm\")\n",
        "        \n",
        "        print(\"  Measurements:\")\n",
        "        for measurement in result['measurements']:\n",
        "            print(f\"    Object {measurement['object_id']}: {measurement['width_mm']:.1f} x {measurement['height_mm']:.1f} mm\")\n",
        "            print(f\"      ({measurement['width_inch']:.2f} x {measurement['height_inch']:.2f} inches)\")\n",
        "else:\n",
        "    print(\"\\nNo results to summarize. Please run the processing cells first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Notes and Instructions\n",
        "\n",
        "This notebook provides a complete standalone object size estimation system that:\n",
        "\n",
        "### Key Features:\n",
        "- **Functional programming approach** - No classes, just functions\n",
        "- **AWS SageMaker compatible** - Runs entirely in the notebook environment\n",
        "- **SAM-based segmentation** - Uses Facebook's Segment Anything Model\n",
        "- **Yellow object detection** - HSV color space filtering\n",
        "- **Simple calibration** - Default px/mm ratio (can be enhanced with ruler detection)\n",
        "- **Visual results** - Clear annotations and measurements\n",
        "\n",
        "### Usage Instructions:\n",
        "1. **Run all cells in sequence** - Start from the top and execute each cell\n",
        "2. **Upload your images** - Place test images in the 'test_images' folder\n",
        "3. **Process images** - Run the processing cells to analyze your images\n",
        "4. **Download results** - Get processed images from the 'output' folder\n",
        "\n",
        "### Customization Options:\n",
        "- **Adjust calibration**: Modify the `px_per_mm` value in the measurement function\n",
        "- **Change color detection**: Modify HSV ranges for different colored objects\n",
        "- **Add ruler detection**: Implement OCR-based ruler detection for better calibration\n",
        "- **Enhance visualization**: Add more detailed annotations and measurements\n",
        "\n",
        "### Supported Image Formats:\n",
        "- JPEG (.jpg, .jpeg)\n",
        "- PNG (.png)\n",
        "- BMP (.bmp)\n",
        "\n",
        "### System Requirements:\n",
        "- Python 3.7+\n",
        "- OpenCV\n",
        "- NumPy\n",
        "- Matplotlib\n",
        "- PyTorch\n",
        "- SAM (Segment Anything Model)\n",
        "- EasyOCR\n",
        "\n",
        "The system is designed to be robust and handle various image qualities and lighting conditions. For best results, ensure good lighting and clear visibility of yellow objects in your images.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
