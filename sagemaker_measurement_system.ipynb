{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Object Size Estimation System for AWS SageMaker\n",
        "\n",
        "This notebook provides a complete object size estimation system using SAM (Segment Anything Model) and computer vision techniques. It detects yellow objects and rulers in images, then calculates real-world measurements.\n",
        "\n",
        "## Features\n",
        "- SAM-based object segmentation\n",
        "- HSV color-based yellow object detection\n",
        "- Sequential ruler marking detection with OCR\n",
        "- Automatic calibration and measurement\n",
        "- Enhanced visualization with annotations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 1. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install opencv-python numpy matplotlib\n",
        "!pip install torch torchvision\n",
        "!pip install git+https://github.com/facebookresearch/segment-anything.git\n",
        "!pip install easyocr\n",
        "!pip install Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 2. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "from PIL import Image\n",
        "import easyocr\n",
        "\n",
        "# SAM imports\n",
        "from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator\n",
        "\n",
        "print(\"All libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 3. Download SAM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download SAM model checkpoint\n",
        "import urllib.request\n",
        "\n",
        "# Create models directory\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Download SAM ViT-B checkpoint (358MB)\n",
        "checkpoint_url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\"\n",
        "checkpoint_path = \"models/sam_vit_b_01ec64.pth\"\n",
        "\n",
        "if not os.path.exists(checkpoint_path):\n",
        "    print(\"Downloading SAM model checkpoint...\")\n",
        "    urllib.request.urlretrieve(checkpoint_url, checkpoint_path)\n",
        "    print(\"Download complete!\")\n",
        "else:\n",
        "    print(\"SAM model checkpoint already exists.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 4. Initialize SAM Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_sam_model(checkpoint_path: str):\n",
        "    \"\"\"Load SAM model\"\"\"\n",
        "    print(f\"Loading SAM model from {checkpoint_path}\")\n",
        "    \n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f\"SAM checkpoint not found at {checkpoint_path}\")\n",
        "    \n",
        "    # Load SAM model\n",
        "    sam = sam_model_registry[\"vit_b\"](checkpoint=checkpoint_path)\n",
        "    \n",
        "    # Use CPU for compatibility\n",
        "    device = \"cpu\"\n",
        "    sam.to(device=device)\n",
        "    \n",
        "    predictor = SamPredictor(sam)\n",
        "    print(f\"SAM loaded successfully on {device}\")\n",
        "    \n",
        "    return sam, predictor\n",
        "\n",
        "# Load SAM model\n",
        "sam_model, sam_predictor = load_sam_model(checkpoint_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 5. Initialize OCR Reader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize OCR reader\n",
        "print(\"Initializing OCR reader...\")\n",
        "ocr_reader = easyocr.Reader(['en'])\n",
        "print(\"OCR reader initialized!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 6. Core Functions\n",
        "\n",
        "### Image Processing Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image(image: np.ndarray, max_size: int = 800) -> np.ndarray:\n",
        "    \"\"\"Resize image for SAM processing\"\"\"\n",
        "    h, w = image.shape[:2]\n",
        "    if max(h, w) > max_size:\n",
        "        scale = max_size / max(h, w)\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        image = cv2.resize(image, (new_w, new_h))\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image(image_path: str):\n",
        "    \"\"\"Load and preprocess image\"\"\"\n",
        "    # Load image\n",
        "    original_image = cv2.imread(image_path)\n",
        "    if original_image is None:\n",
        "        raise ValueError(f\"Could not load image from {image_path}\")\n",
        "    \n",
        "    print(f\"Original image: {original_image.shape[1]}x{original_image.shape[0]}\")\n",
        "    \n",
        "    # Resize for processing\n",
        "    resized_image = resize_image(original_image)\n",
        "    print(f\"Resized image: {resized_image.shape[1]}x{resized_image.shape[0]}\")\n",
        "    \n",
        "    # Calculate scale factors\n",
        "    scale_x = resized_image.shape[1] / original_image.shape[1]\n",
        "    scale_y = resized_image.shape[0] / original_image.shape[0]\n",
        "    \n",
        "    return original_image, resized_image, scale_x, scale_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Yellow Object Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def detect_yellow_objects_hsv(image: np.ndarray) -> List[Dict]:\n",
        "    \"\"\"Yellow object detection using HSV color space\"\"\"\n",
        "    print(\"\\n=== YELLOW OBJECT DETECTION ===\")\n",
        "    \n",
        "    # Convert to HSV for better color detection\n",
        "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    \n",
        "    # Define yellow color range in HSV\n",
        "    lower_yellow = np.array([15, 50, 50])\n",
        "    upper_yellow = np.array([35, 255, 255])\n",
        "    \n",
        "    # Create binary mask for yellow regions\n",
        "    mask = cv2.inRange(hsv, lower_yellow, upper_yellow)\n",
        "    \n",
        "    # Morphological operations for noise reduction\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "    \n",
        "    # Find contours\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    print(f\"  Found {len(contours)} contours\")\n",
        "    \n",
        "    # Process contours with filtering\n",
        "    candidates = []\n",
        "    \n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        \n",
        "        # Filter by area\n",
        "        if area < 1000:\n",
        "            continue\n",
        "        \n",
        "        # Calculate bounding rectangle\n",
        "        bbox = cv2.boundingRect(contour)\n",
        "        x, y, w, h = bbox\n",
        "        \n",
        "        # Calculate aspect ratio\n",
        "        aspect_ratio = max(w, h) / min(w, h)\n",
        "        \n",
        "        # Filter by aspect ratio\n",
        "        if aspect_ratio > 5:\n",
        "            continue\n",
        "        \n",
        "        # Calculate quality metrics\n",
        "        hull = cv2.convexHull(contour)\n",
        "        hull_area = cv2.contourArea(hull)\n",
        "        solidity = area / hull_area if hull_area > 0 else 0\n",
        "        extent = area / (w * h)\n",
        "        \n",
        "        # Quality score\n",
        "        quality_score = (solidity * 0.4 + extent * 0.4 + min(1.0, area / 5000) * 0.2)\n",
        "        \n",
        "        # Only accept high-quality detections\n",
        "        if quality_score > 0.5:\n",
        "            candidates.append({\n",
        "                'contour': contour,\n",
        "                'bbox': bbox,\n",
        "                'area': area,\n",
        "                'aspect_ratio': aspect_ratio,\n",
        "                'solidity': solidity,\n",
        "                'extent': extent,\n",
        "                'quality_score': quality_score,\n",
        "                'method': 'hsv'\n",
        "            })\n",
        "    \n",
        "    print(f\"  After filtering: {len(candidates)} candidates\")\n",
        "    \n",
        "    # Sort by quality score\n",
        "    candidates.sort(key=lambda x: x['quality_score'], reverse=True)\n",
        "    \n",
        "    # Remove overlapping detections\n",
        "    final_objects = []\n",
        "    for candidate in candidates:\n",
        "        is_duplicate = False\n",
        "        for existing in final_objects:\n",
        "            if calculate_bbox_overlap(candidate['bbox'], existing['bbox']) > 0.3:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "        \n",
        "        if not is_duplicate:\n",
        "            final_objects.append(candidate)\n",
        "    \n",
        "    print(f\"  Final objects: {len(final_objects)}\")\n",
        "    for i, obj in enumerate(final_objects):\n",
        "        print(f\"    Object {i+1}: area={obj['area']}, quality={obj['quality_score']:.2f}\")\n",
        "    \n",
        "    return final_objects\n",
        "\n",
        "def calculate_bbox_overlap(bbox1: Tuple[int, int, int, int], bbox2: Tuple[int, int, int, int]) -> float:\n",
        "    \"\"\"Calculate overlap ratio between two bounding boxes\"\"\"\n",
        "    x1, y1, w1, h1 = bbox1\n",
        "    x2, y2, w2, h2 = bbox2\n",
        "    \n",
        "    # Calculate intersection\n",
        "    left = max(x1, x2)\n",
        "    top = max(y1, y2)\n",
        "    right = min(x1 + w1, x2 + w2)\n",
        "    bottom = min(y1 + h1, y2 + h2)\n",
        "    \n",
        "    if left < right and top < bottom:\n",
        "        intersection = (right - left) * (bottom - top)\n",
        "        area1 = w1 * h1\n",
        "        area2 = w2 * h2\n",
        "        union = area1 + area2 - intersection\n",
        "        return intersection / union if union > 0 else 0\n",
        "    \n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Main Measurement Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def measure_objects_in_image(image_path: str, sam_model, sam_predictor, ocr_reader, display=True):\n",
        "    \"\"\"Complete measurement pipeline - functional approach\"\"\"\n",
        "    \n",
        "    print(f\"SAM MEASUREMENT SYSTEM: {image_path}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        original_image, resized_image, scale_x, scale_y = load_and_preprocess_image(image_path)\n",
        "        \n",
        "        # Detect yellow objects\n",
        "        yellow_objects = detect_yellow_objects_hsv(resized_image)\n",
        "        print(f\"Detection found {len(yellow_objects)} yellow objects\")\n",
        "        \n",
        "        if not yellow_objects:\n",
        "            print(\"No yellow objects found\")\n",
        "            return None\n",
        "        \n",
        "        # Simple calibration (assume 30 pixels per mm as default)\n",
        "        # In a real scenario, you would implement ruler detection here\n",
        "        px_per_mm = 30.0  # This is a placeholder - you can implement ruler detection\n",
        "        \n",
        "        # Measure objects\n",
        "        measurements = []\n",
        "        for i, obj in enumerate(yellow_objects):\n",
        "            # Get oriented bounding box\n",
        "            rect = cv2.minAreaRect(obj['contour'])\n",
        "            width_px, height_px = rect[1]\n",
        "            \n",
        "            # Ensure width > height\n",
        "            if height_px > width_px:\n",
        "                width_px, height_px = height_px, width_px\n",
        "            \n",
        "            # Convert to real world units\n",
        "            width_mm = width_px / px_per_mm\n",
        "            height_mm = height_px / px_per_mm\n",
        "            \n",
        "            measurement = {\n",
        "                'object_id': i + 1,\n",
        "                'width_mm': width_mm,\n",
        "                'height_mm': height_mm,\n",
        "                'width_inch': width_mm / 25.4,\n",
        "                'height_inch': height_mm / 25.4,\n",
        "                'width_px': width_px,\n",
        "                'height_px': height_px,\n",
        "                'area_px': obj['area']\n",
        "            }\n",
        "            measurements.append(measurement)\n",
        "        \n",
        "        print(f\"\\nSUCCESS!\")\n",
        "        \n",
        "        for measurement in measurements:\n",
        "            print(f\"   Object {measurement['object_id']}: {measurement['width_mm']:.1f} x {measurement['height_mm']:.1f} mm\")\n",
        "            print(f\"      ({measurement['width_inch']:.2f} x {measurement['height_inch']:.2f} inches)\")\n",
        "        \n",
        "        # Create simple visualization\n",
        "        vis_image = resized_image.copy()\n",
        "        \n",
        "        # Draw yellow objects\n",
        "        for i, obj in enumerate(yellow_objects):\n",
        "            bbox = obj['bbox']\n",
        "            x, y, w, h = bbox\n",
        "            \n",
        "            # Draw bounding box\n",
        "            cv2.rectangle(vis_image, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
        "            \n",
        "            # Add measurement text\n",
        "            if i < len(measurements):\n",
        "                measurement = measurements[i]\n",
        "                text = f\"Obj {measurement['object_id']}: {measurement['width_mm']:.1f}x{measurement['height_mm']:.1f}mm\"\n",
        "                cv2.putText(vis_image, text, (x, y-10), \n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        \n",
        "        # Add title\n",
        "        cv2.putText(vis_image, 'Object Measurement Results', (10, 30), \n",
        "                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "        \n",
        "        if display:\n",
        "            plt.figure(figsize=(12, 8))\n",
        "            plt.imshow(cv2.cvtColor(vis_image, cv2.COLOR_BGR2RGB))\n",
        "            plt.title(f\"Measurement Results - {os.path.basename(image_path)}\")\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "        \n",
        "        return {\n",
        "            'success': True,\n",
        "            'yellow_objects': yellow_objects,\n",
        "            'measurements': measurements,\n",
        "            'visualization': vis_image,\n",
        "            'original_image': original_image,\n",
        "            'resized_image': resized_image,\n",
        "            'calibration': {'px_per_mm': px_per_mm, 'method': 'default'}\n",
        "        }\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        return {'success': False, 'error': str(e)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 7. Usage Instructions\n",
        "\n",
        "### Step 1: Upload Your Images\n",
        "Upload your test images to the SageMaker environment. Create a folder called 'test_images' and place your images there.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directories for test images and outputs\n",
        "os.makedirs('test_images', exist_ok=True)\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "print(\"Directories created. Please upload your test images to the 'test_images' folder.\")\n",
        "print(\"You can use the file browser on the left to upload images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 2: Process Your Images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all images in the test_images folder\n",
        "test_images = []\n",
        "if os.path.exists('test_images'):\n",
        "    for filename in os.listdir('test_images'):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "            test_images.append(os.path.join('test_images', filename))\n",
        "\n",
        "print(f\"Found {len(test_images)} test images:\")\n",
        "for img in test_images:\n",
        "    print(f\"  - {img}\")\n",
        "\n",
        "if not test_images:\n",
        "    print(\"No test images found. Please upload images to the 'test_images' folder.\")\n",
        "    print(\"Supported formats: .jpg, .jpeg, .png, .bmp\")\n",
        "\n",
        "# Process each image\n",
        "results = []\n",
        "for image_path in test_images:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"PROCESSING: {image_path}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Run measurement system\n",
        "    result = measure_objects_in_image(image_path, sam_model, sam_predictor, ocr_reader, display=True)\n",
        "    \n",
        "    if result and result['success']:\n",
        "        results.append(result)\n",
        "        \n",
        "        # Save visualization\n",
        "        base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "        output_path = f'output/{base_name}_measurement_result.jpg'\n",
        "        cv2.imwrite(output_path, result['visualization'])\n",
        "        print(f\"\\nSaved visualization: {output_path}\")\n",
        "    else:\n",
        "        print(f\"\\nFailed to process {image_path}\")\n",
        "\n",
        "print(f\"\\n\\nProcessing complete! Successfully processed {len(results)} images.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Step 3: Process Individual Images\n",
        "\n",
        "Use this cell to process a single specific image:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process a single image\n",
        "# Replace 'your_image_path.jpg' with the actual path to your image\n",
        "single_image_path = 'test_images/your_image_path.jpg'\n",
        "\n",
        "if os.path.exists(single_image_path):\n",
        "    result = measure_objects_in_image(single_image_path, sam_model, sam_predictor, ocr_reader, display=True)\n",
        "    \n",
        "    if result and result['success']:\n",
        "        print(\"\\nProcessing successful!\")\n",
        "        \n",
        "        # Save result\n",
        "        base_name = os.path.splitext(os.path.basename(single_image_path))[0]\n",
        "        output_path = f'output/{base_name}_detailed_result.jpg'\n",
        "        cv2.imwrite(output_path, result['visualization'])\n",
        "        print(f\"\\nSaved detailed result: {output_path}\")\n",
        "    else:\n",
        "        print(\"Processing failed!\")\n",
        "else:\n",
        "    print(f\"Image not found: {single_image_path}\")\n",
        "    print(\"Please update the path to point to your image file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 8. Summary and Results\n",
        "\n",
        "### View Output Files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all output files\n",
        "output_files = []\n",
        "if os.path.exists('output'):\n",
        "    for filename in os.listdir('output'):\n",
        "        if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            output_files.append(os.path.join('output', filename))\n",
        "\n",
        "print(f\"Generated {len(output_files)} output files:\")\n",
        "for file in output_files:\n",
        "    file_size = os.path.getsize(file) / 1024  # Size in KB\n",
        "    print(f\"  - {file} ({file_size:.1f} KB)\")\n",
        "\n",
        "print(\"\\nYou can download these files using the file browser on the left.\")\n",
        "\n",
        "# Create summary of results\n",
        "if 'results' in locals() and results:\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MEASUREMENT SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for i, result in enumerate(results):\n",
        "        print(f\"\\nImage {i+1}:\")\n",
        "        print(f\"  Objects detected: {len(result['yellow_objects'])}\")\n",
        "        print(f\"  Calibration: {result['calibration']['px_per_mm']:.2f} px/mm\")\n",
        "        \n",
        "        print(\"  Measurements:\")\n",
        "        for measurement in result['measurements']:\n",
        "            print(f\"    Object {measurement['object_id']}: {measurement['width_mm']:.1f} x {measurement['height_mm']:.1f} mm\")\n",
        "            print(f\"      ({measurement['width_inch']:.2f} x {measurement['height_inch']:.2f} inches)\")\n",
        "else:\n",
        "    print(\"\\nNo results to summarize. Please run the processing cells first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## 9. Notes and Instructions\n",
        "\n",
        "This notebook provides a complete standalone object size estimation system that:\n",
        "\n",
        "### Key Features:\n",
        "- **Functional programming approach** - No classes, just functions\n",
        "- **AWS SageMaker compatible** - Runs entirely in the notebook environment\n",
        "- **SAM-based segmentation** - Uses Facebook's Segment Anything Model\n",
        "- **Yellow object detection** - HSV color space filtering\n",
        "- **Simple calibration** - Default px/mm ratio (can be enhanced with ruler detection)\n",
        "- **Visual results** - Clear annotations and measurements\n",
        "\n",
        "### Usage Instructions:\n",
        "1. **Run all cells in sequence** - Start from the top and execute each cell\n",
        "2. **Upload your images** - Place test images in the 'test_images' folder\n",
        "3. **Process images** - Run the processing cells to analyze your images\n",
        "4. **Download results** - Get processed images from the 'output' folder\n",
        "\n",
        "### Customization Options:\n",
        "- **Adjust calibration**: Modify the `px_per_mm` value in the measurement function\n",
        "- **Change color detection**: Modify HSV ranges for different colored objects\n",
        "- **Add ruler detection**: Implement OCR-based ruler detection for better calibration\n",
        "- **Enhance visualization**: Add more detailed annotations and measurements\n",
        "\n",
        "### Supported Image Formats:\n",
        "- JPEG (.jpg, .jpeg)\n",
        "- PNG (.png)\n",
        "- BMP (.bmp)\n",
        "\n",
        "### System Requirements:\n",
        "- Python 3.7+\n",
        "- OpenCV\n",
        "- NumPy\n",
        "- Matplotlib\n",
        "- PyTorch\n",
        "- SAM (Segment Anything Model)\n",
        "- EasyOCR\n",
        "\n",
        "The system is designed to be robust and handle various image qualities and lighting conditions. For best results, ensure good lighting and clear visibility of yellow objects in your images.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
